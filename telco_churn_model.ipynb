{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTINGS, IMPORT AND LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERVIEW DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nline = '-'*80\\nprint('HEAD')\\nprint(df.head())\\nprint(line)\\nprint('INFO')\\nprint(df.info())\\nprint(line)\\nprint('DESCRIBE')\\nprint(df.describe().T)\\nprint(line)\\nprint('DESCRIBE NON NUMERIC')\\nprint(df.describe(include=['object', 'bool']))\\nprint(line)\\nprint('COLUMNS')\\nprint(df.columns)\\nprint(line)\\n\""
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "'''\n",
    "line = '-'*80\n",
    "print('HEAD')\n",
    "print(df.head())\n",
    "print(line)\n",
    "print('INFO')\n",
    "print(df.info())\n",
    "print(line)\n",
    "print('DESCRIBE')\n",
    "print(df.describe().T)\n",
    "print(line)\n",
    "print('DESCRIBE NON NUMERIC')\n",
    "print(df.describe(include=['object', 'bool']))\n",
    "print(line)\n",
    "print('COLUMNS')\n",
    "print(df.columns)\n",
    "print(line)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING & CORRECTION MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nprint(\\'COUNT NULL COLUMNS\\')\\nprint(df.isnull().sum())       # Count the Null Columns\\n## print(pd.isnull(df).sum())           # outra forma de fazer\\n## print(df[df[\"gender\"].isnull()])    # Single Column Is Null\\n# print(df[df.isnull().any(axis=1)].head())    # dataframe com All Null Columns\\n'"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "'''\n",
    "print('COUNT NULL COLUMNS')\n",
    "print(df.isnull().sum())       # Count the Null Columns\n",
    "## print(pd.isnull(df).sum())           # outra forma de fazer\n",
    "## print(df[df[\"gender\"].isnull()])    # Single Column Is Null\n",
    "# print(df[df.isnull().any(axis=1)].head())    # dataframe com All Null Columns\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING & CORRECTION MISMATCHED VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select_dtypes(include=[\"float\", 'int64'])   # verifica quais colunas são numéricas\n",
    "# print(df.select_dtypes(include=np.number))   # verifica quais colunas são numéricas. equivalente a anterior\n",
    "\n",
    "# print(df[df.TotalCharges.str.isspace()]['TotalCharges'])     # identifica campos numéricos com espaço \n",
    "# a = df['TotalCharges'].str.findall(r'[^0-9.]')   # verifica caracteres não numéricos e diferente de ponto\n",
    "# for c, x in enumerate(a):\n",
    "#     if len(x) > 0:\n",
    "#         print(c, x)    # mostra linhas com caracteres não numéricos\n",
    "df['TotalCharges'][df['TotalCharges'] == ' '] = '0'  # verifica as linhas 'TotalCharges' == ' ' e atribui '0'\n",
    "## df['TotalCharges'] = df['TotalCharges'].replace(r'\\s+', np.nan, regex=True) #outra forma: mudar espaços p NaN\n",
    "## df['TotalCharges']=df['TotalCharges'].fillna(df['TotalCharges'].median())     # uma alternativa é colocar a mediana ao invés de zero\n",
    "\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])  # transforma a coluna de string para numérico\n",
    "## df[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)    # outra forma de converter para float\n",
    "\n",
    "## type(df.TotalCharges[0])             # verifica o tipo de um determinado campo olhando a primera linha. \n",
    "## print(df.TotalCharges)    # verifica se coluna foi convertida para float\n",
    "\n",
    "#replace values\n",
    "df[\"SeniorCitizen\"] = df[\"SeniorCitizen\"].replace({1:\"Yes\",0:\"No\"})\n",
    "\n",
    "#replace 'No internet service' to No for the following columns\n",
    "replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "for i in replace_cols : \n",
    "    df[i]  = df[i].replace({'No internet service' : 'No'})\n",
    "\n",
    "df['MultipleLines']  = df['MultipleLines'].replace({'No phone service' : 'No'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CHURN VALUE COUNTS\nNo    0.73\nYes   0.27\nName: Churn, dtype: float64\n"
    }
   ],
   "source": [
    "# print(df.info())\n",
    "\n",
    "# Separating catagorical and numerical columns\n",
    "Id_col     = ['customerID']\n",
    "target_col = [\"Churn\"]\n",
    "cat_cols   = df.nunique()[df.nunique() < 6].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols if x not in target_col]\n",
    "num_cols   = [x for x in df.columns if x not in cat_cols + target_col + Id_col]\n",
    "\n",
    "# Binary columns with 2 values\n",
    "bin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\n",
    "#Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "# print('CAT', cat_cols, 'NUM', num_cols, 'BIN', bin_cols, 'MULTI', multi_cols)\n",
    "\n",
    "print('CHURN VALUE COUNTS')\n",
    "print(df.Churn.value_counts(normalize=True))     # mostra distribuição do target normalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HISTOGRAM - NUMERIC COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nfor c in num_cols:\\n    plt.figure()\\n    plt.title(c)\\n    plt.hist(df[df.Churn == 'Yes'][c], normed=True, bins=20, color='r', alpha=0.5, label='Churn')\\n    plt.hist(df[df.Churn == 'No'][c], normed=True, bins=20, color='g', alpha=0.5, label='No Churn')\\n    plt.legend()\\n    plt.figure()\\n    plt.title(c)\\n    plt.hist(df[df.Churn == 'Yes'][c], normed=True, bins=20, color='r', alpha=0.5, label='Churn')\\n    plt.legend()\\n    plt.figure()\\n    plt.title(c)\\n    plt.hist(df[df.Churn == 'No'][c], normed=True, bins=20, color='g', alpha=0.5, label='No Churn')\\n    plt.legend()\\n\""
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "'''\n",
    "for c in num_cols:\n",
    "    plt.figure()\n",
    "    plt.title(c)\n",
    "    plt.hist(df[df.Churn == 'Yes'][c], normed=True, bins=20, color='r', alpha=0.5, label='Churn')\n",
    "    plt.hist(df[df.Churn == 'No'][c], normed=True, bins=20, color='g', alpha=0.5, label='No Churn')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.title(c)\n",
    "    plt.hist(df[df.Churn == 'Yes'][c], normed=True, bins=20, color='r', alpha=0.5, label='Churn')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.title(c)\n",
    "    plt.hist(df[df.Churn == 'No'][c], normed=True, bins=20, color='g', alpha=0.5, label='No Churn')\n",
    "    plt.legend()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAR PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nfor c in cat_cols:\\n    # print(df[c].value_counts())\\n    # print(df[c].value_counts(normalize=True))     # mostra distribuição do target normalizada\\n\\n    sum_values = df.groupby(['Churn', c]).agg(np.count_nonzero).iloc[:,0]\\n    yes_values = sum_values.loc['Yes'].values\\n    no_values = sum_values.loc['No'].values\\n    xvals = list(sum_values.loc['Yes'].index)\\n    yes_values_norm = []\\n    no_values_norm = []\\n    for x in xvals:\\n        tot = sum_values.loc[:,x].sum()\\n        yes_values_norm.append(sum_values.loc['Yes',x] / tot)\\n        no_values_norm.append(sum_values.loc['No',x] / tot)\\n        \\n    # xvals_str = [str(x) for x in xvals]\\n    plt.figure(figsize=(10,6))\\n    plt.xlabel(c,  fontsize=12)\\n    bars_yes = plt.bar(xvals, yes_values, width=0.5, label='Churn Yes', color='r', alpha=0.7)\\n    bars_no = plt.bar(xvals, no_values, width=0.5, bottom=yes_values, label='Churn No', color='g', alpha=0.7)\\n    plt.legend()\\n\\n    # direct label each bar with Y axis values\\n    for i, bar in enumerate(bars_yes):\\n        height = bar.get_height()\\n        width = bar.get_width()\\n        plt.gca().text(bar.get_x() + width/2, height * (1/2), str(int(height)) + ' , ' + str(int(yes_values_norm[i]*100)) + '%', ha='center', \\n        color='black', fontsize=11)\\n\\n    for i, bar in enumerate(bars_no):\\n        height = bar.get_height()\\n        width = bar.get_width()\\n        plt.gca().text(bar.get_x() + width/2, (height * (1/2)) + yes_values[i], str(int(height)) + ' , ' + str(int(no_values_norm[i]*100)) + '%', \\n        ha='center', color='black', fontsize=11)\\n\""
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "'''\n",
    "for c in cat_cols:\n",
    "    # print(df[c].value_counts())\n",
    "    # print(df[c].value_counts(normalize=True))     # mostra distribuição do target normalizada\n",
    "\n",
    "    sum_values = df.groupby(['Churn', c]).agg(np.count_nonzero).iloc[:,0]\n",
    "    yes_values = sum_values.loc['Yes'].values\n",
    "    no_values = sum_values.loc['No'].values\n",
    "    xvals = list(sum_values.loc['Yes'].index)\n",
    "    yes_values_norm = []\n",
    "    no_values_norm = []\n",
    "    for x in xvals:\n",
    "        tot = sum_values.loc[:,x].sum()\n",
    "        yes_values_norm.append(sum_values.loc['Yes',x] / tot)\n",
    "        no_values_norm.append(sum_values.loc['No',x] / tot)\n",
    "        \n",
    "    # xvals_str = [str(x) for x in xvals]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.xlabel(c,  fontsize=12)\n",
    "    bars_yes = plt.bar(xvals, yes_values, width=0.5, label='Churn Yes', color='r', alpha=0.7)\n",
    "    bars_no = plt.bar(xvals, no_values, width=0.5, bottom=yes_values, label='Churn No', color='g', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "    # direct label each bar with Y axis values\n",
    "    for i, bar in enumerate(bars_yes):\n",
    "        height = bar.get_height()\n",
    "        width = bar.get_width()\n",
    "        plt.gca().text(bar.get_x() + width/2, height * (1/2), str(int(height)) + ' , ' + str(int(yes_values_norm[i]*100)) + '%', ha='center', \n",
    "        color='black', fontsize=11)\n",
    "\n",
    "    for i, bar in enumerate(bars_no):\n",
    "        height = bar.get_height()\n",
    "        width = bar.get_width()\n",
    "        plt.gca().text(bar.get_x() + width/2, (height * (1/2)) + yes_values[i], str(int(height)) + ' , ' + str(int(no_values_norm[i]*100)) + '%', \n",
    "        ha='center', color='black', fontsize=11)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "#Duplicating columns for multi value columns\n",
    "df = pd.get_dummies(data = df,columns = multi_cols)\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(df[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_og = df.copy()\n",
    "df = df.drop(columns = num_cols,axis = 1)\n",
    "df = df.merge(scaled,left_index=True,right_index=True,how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\n\\ndf['Churn'][df['Churn'] == 'No'] = 0     # atriui 0 onde era 'No'\\ndf['Churn'][df['Churn'] == 'Yes'] = 1\\n# df['Churn'] = df['Churn'].replace({'Yes': 1, 'No': 0})     # forma alternativa em 1 linha\\n\\n\\ncol = 'Dependents'\\ndf[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\\n# df['Churn']=df['Churn'].replace('No',0)    # outra forma de fazer\\ndf[col][df[col] == 'Yes'] = 1\\n\\ncol = 'Partner'\\ndf[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\\ndf[col][df[col] == 'Yes'] = 1 \\n\\ncol = 'PaperlessBilling'\\ndf[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\\ndf[col][df[col] == 'Yes'] = 1  \\n\\nle = preprocessing.LabelEncoder()\\ncol = 'TechSupport'\\n# le.fit(df[col])\\ndf.at[:,col] = le.fit_transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'StreamingTV'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'StreamingMovies'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'OnlineSecurity'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'DeviceProtection'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'Contract'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_Contract = {'Month-to-month': 0, 'Two year': 2, 'One year': 1}\\n\\ncol = 'PaymentMethod'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_PaymentMethod = {'Electronic check': 2, 'Mailed check': 3, 'Bank transfer (automatic)': 0, 'Credit card (automatic)': 1}\\n\\ncol = 'gender'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'Male': 1, 'Female': 0}\\n\\ncol = 'InternetService'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_PaymentMethod = {'Fiber optic': 1, 'DSL': 0, 'No': 2}\\n\\ncol = 'OnlineBackup'\\nle.fit(df[col])\\ndf.at[:,col] = le.transform(df[col])\\ndict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\\n\\ncol = 'PhoneService'\\ndf[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\\ndf[col][df[col] == 'Yes'] = 1\\n\""
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "df['Churn'][df['Churn'] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df['Churn'][df['Churn'] == 'Yes'] = 1\n",
    "# df['Churn'] = df['Churn'].replace({'Yes': 1, 'No': 0})     # forma alternativa em 1 linha\n",
    "\n",
    "\n",
    "col = 'Dependents'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "# df['Churn']=df['Churn'].replace('No',0)    # outra forma de fazer\n",
    "df[col][df[col] == 'Yes'] = 1\n",
    "\n",
    "col = 'Partner'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1 \n",
    "\n",
    "col = 'PaperlessBilling'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1  \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "col = 'TechSupport'\n",
    "# le.fit(df[col])\n",
    "df.at[:,col] = le.fit_transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'StreamingTV'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'StreamingMovies'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'OnlineSecurity'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'DeviceProtection'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'Contract'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_Contract = {'Month-to-month': 0, 'Two year': 2, 'One year': 1}\n",
    "\n",
    "col = 'PaymentMethod'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_PaymentMethod = {'Electronic check': 2, 'Mailed check': 3, 'Bank transfer (automatic)': 0, 'Credit card (automatic)': 1}\n",
    "\n",
    "col = 'gender'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'Male': 1, 'Female': 0}\n",
    "\n",
    "col = 'InternetService'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_PaymentMethod = {'Fiber optic': 1, 'DSL': 0, 'No': 2}\n",
    "\n",
    "col = 'OnlineBackup'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'PhoneService'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "#       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "#       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "# features = ['Contract', 'MonthlyCharges', 'tenure', 'TotalCharges', 'OnlineSecurity', 'TechSupport', 'InternetService',  'PaymentMethod',  'SeniorCitizen', 'Dependents', 'Partner', 'OnlineBackup', 'DeviceProtection', 'PaperlessBilling']\n",
    "features = [i for i in df.columns if i not in Id_col + target_col]\n",
    "X = df[features]\n",
    "y = df['Churn']\n",
    "# y = y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling TEchnique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_X = df[features]\n",
    "smote_Y = df[target_col]\n",
    "\n",
    "#Split train and test data\n",
    "smote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y, test_size = .25 , random_state = 111)\n",
    "\n",
    "#oversampling minority class using smote\n",
    "os = SMOTE(random_state = 0)\n",
    "os_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\n",
    "os_smote_X = pd.DataFrame(data = os_smote_X,columns=features)\n",
    "os_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_base = GradientBoostingClassifier()\n",
    "\n",
    "rfe = RFE(clf_base,10)\n",
    "rfe = rfe.fit(os_smote_X,os_smote_Y.values.ravel())\n",
    "\n",
    "rfe.support_\n",
    "rfe.ranking_\n",
    "\n",
    "#identified columns Recursive Feature Elimination\n",
    "idc_rfe = pd.DataFrame({\"rfe_support\" :rfe.support_,\n",
    "                       \"columns\" : [i for i in df.columns if i not in Id_col + target_col],\n",
    "                       \"ranking\" : rfe.ranking_,\n",
    "                      })\n",
    "features = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n",
    "X = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nOHE = False\\nif OHE:\\n    col = 'Contract'\\n    df_ohe = df[features]\\n    ohe = OneHotEncoder(sparse=False) # categorical_features = boolean...\\n    # for col in features_ohe:\\n    le.fit(df[col])\\n    col2 = col + '_e'\\n    df.at[:,col2] = le.transform(df[col])\\n    colunas = list(df.groupby([col, col2]).max().index.levels[0])         \\n\\n    X_ohe = ohe.fit_transform(df[col2].values.reshape(-1, 1)) # It returns an numpy array                \\n    new = pd.DataFrame(X_ohe, columns=colunas, index=df.index)\\n    df_ohe = pd.merge(new, df_ohe, how='inner', left_index=True, right_index=True)\\n    # df = df_ohe.copy()\\n    df = df_ohe.drop(col, axis=1)\\nelse:\\n    df = df[features]\\n\""
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "'''\n",
    "OHE = False\n",
    "if OHE:\n",
    "    col = 'Contract'\n",
    "    df_ohe = df[features]\n",
    "    ohe = OneHotEncoder(sparse=False) # categorical_features = boolean...\n",
    "    # for col in features_ohe:\n",
    "    le.fit(df[col])\n",
    "    col2 = col + '_e'\n",
    "    df.at[:,col2] = le.transform(df[col])\n",
    "    colunas = list(df.groupby([col, col2]).max().index.levels[0])         \n",
    "\n",
    "    X_ohe = ohe.fit_transform(df[col2].values.reshape(-1, 1)) # It returns an numpy array                \n",
    "    new = pd.DataFrame(X_ohe, columns=colunas, index=df.index)\n",
    "    df_ohe = pd.merge(new, df_ohe, how='inner', left_index=True, right_index=True)\n",
    "    # df = df_ohe.copy()\n",
    "    df = df_ohe.drop(col, axis=1)\n",
    "else:\n",
    "    df = df[features]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# norm = False\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_features=5, n_jobs = -1, random_state = 0)  # n_estimators=600, \n",
    "# clf = RandomForestClassifier(criterion='entropy',n_estimators=1000,max_depth=100,oob_score=True,random_state=42)\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, max_depth = 4, random_state = 0)\n",
    "# clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "# clf = LogisticRegression(C=0.1)\n",
    "\n",
    "# norm = True\n",
    "# clf = MLPClassifier(hidden_layer_sizes = [100, 100], solver='adam',  activation = 'tanh', alpha=0.00001, random_state = 0)   \n",
    "   \n",
    "# Fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "# if norm:\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_proba_lr = clf.predict_proba(X_test)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr[:,1])\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "clr = classification_report(y_test, y_predicted, target_names = ['0', '1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "score train: 0.8436198409693298\nscore test: 0.7768313458262351\nAUC 0.8244358324985773\n[[1131  167]\n [ 226  237]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.87      0.85      1298\n           1       0.59      0.51      0.55       463\n\n    accuracy                           0.78      1761\n   macro avg       0.71      0.69      0.70      1761\nweighted avg       0.77      0.78      0.77      1761\n\n"
    }
   ],
   "source": [
    "print('score train:', clf.score(X_train, y_train))\n",
    "print('score test:', clf.score(X_test, y_test))\n",
    "print('AUC', roc_auc_lr)\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print(clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                importance\nContract_Month-to-month           0.388247\ntenure                            0.158231\nTotalCharges                      0.136396\nMonthlyCharges                    0.135372\nInternetService_Fiber optic       0.098715\nPaymentMethod_Electronic check    0.040301\nInternetService_No                0.017559\nOnlineSecurity                    0.016041\nContract_Two year                 0.004741\nContract_One year                 0.004396",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Contract_Month-to-month</th>\n      <td>0.388247</td>\n    </tr>\n    <tr>\n      <th>tenure</th>\n      <td>0.158231</td>\n    </tr>\n    <tr>\n      <th>TotalCharges</th>\n      <td>0.136396</td>\n    </tr>\n    <tr>\n      <th>MonthlyCharges</th>\n      <td>0.135372</td>\n    </tr>\n    <tr>\n      <th>InternetService_Fiber optic</th>\n      <td>0.098715</td>\n    </tr>\n    <tr>\n      <th>PaymentMethod_Electronic check</th>\n      <td>0.040301</td>\n    </tr>\n    <tr>\n      <th>InternetService_No</th>\n      <td>0.017559</td>\n    </tr>\n    <tr>\n      <th>OnlineSecurity</th>\n      <td>0.016041</td>\n    </tr>\n    <tr>\n      <th>Contract_Two year</th>\n      <td>0.004741</td>\n    </tr>\n    <tr>\n      <th>Contract_One year</th>\n      <td>0.004396</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "feature_importances1 = pd.DataFrame(clf.feature_importances_,index = X_train.columns,columns=['importance']).sort_values('importance',ascending=False)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "feature_importances1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# X.mean()\n",
    "# X_test\n",
    "# scaled = std.fit_transform(df[num_cols])\n",
    "# scaled = pd.DataFrame(scaled,columns=num_cols)\n",
    "X_sim = pd.DataFrame(columns=X_test.columns)\n",
    "X_sim.at[0, 'OnlineSecurity'] = 0\n",
    "X_sim.at[0, 'InternetService_Fiber optic'] = 1\n",
    "X_sim.at[0, 'InternetService_No'] = 0\n",
    "X_sim.at[0, 'Contract_Month-to-month'] = 1\n",
    "X_sim.at[0, 'Contract_One year'] = 0\n",
    "X_sim.at[0, 'Contract_Two year'] = 0\n",
    "X_sim.at[0, 'PaymentMethod_Electronic check'] = 1\n",
    "X_sim.at[0, 'tenure'] = -1\n",
    "X_sim.at[0, 'MonthlyCharges'] = -1\n",
    "X_sim.at[0, 'TotalCharges'] = -1\n",
    "# X_sim\n",
    "y_predicted_sim = clf.predict(X_sim)\n",
    "y_predicted_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['OnlineSecurity', 'InternetService_Fiber optic', 'InternetService_No',\n       'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year',\n       'PaymentMethod_Electronic check', 'tenure', 'MonthlyCharges',\n       'TotalCharges'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X_sim.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorias\n",
    "- organizar e deixar modelo\n",
    "\n",
    "- https://www.kaggle.com/pavanraj159/telecom-customer-churn-prediction\n",
    "- Recursive Feature Elimination (BOM)\n",
    "- PCA - principal components\n",
    "- Threshold Plot \n",
    "- Univariate Selection\n",
    "\n",
    "- cross validation (avaliar - tenho dúvidas)\n",
    "- scatter plot matrix for numerical columns (interesante mas não mandatório)\n",
    "- radar chart?? (não prioritário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}