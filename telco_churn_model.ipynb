{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 20                        # id da coluna em análise\n",
    "# c = df.columns[c_id]\n",
    "c = 'Contract'\n",
    "# print(df[c].value_counts())\n",
    "# print(df[c].describe())\n",
    "# print(type(df[c][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(df[c], normed=False, bins=20, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de Barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(9,5))\n",
    "# plt.bar(df[c].value_counts().index, df[c].value_counts(), width=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.isnull(df).sum())     # Count the Null Columns\n",
    "# print(df[df[\"gender\"].isnull()])    # Single Column Is Null\n",
    "# print(df[df.isnull().any(axis=1)].head())    # All Null Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Mismatched Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['TotalCharges'].str.findall(r'\\D')   # verifica se há algum caracter na string que não é numérico\n",
    "# type(df.TotalCharges[0])             # verifica o tipo de um determinado campo olhando a primera linha. Neste exemplo campo se chama 'TotalCharges'\n",
    "# print(df.tenure.str.isnumeric())     # check se é numérico se a coluna for string. não este o caso aqui. ainda tenho dúvidas com esta função\n",
    "# df.select_dtypes(include=[\"float\", 'int64'])   # verifica quais colunas são numéricas\n",
    "# df.select_dtypes(include=np.number)   # verifica quais colunas são numéricas. equivalente a anterior\n",
    "# df.tenure                        # neste exemplo campo = 'tenure'. nesta função olhe o tipo do dado no final no campo dtype: int64 ou float ou str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df['TotalCharges'][df['TotalCharges'] == ' '] = '0'     # verifica as linhas cujo 'TotalCharges' == ' ' e atribui '0'\n",
    "# df[df['TotalCharges'] == '0']['TotalCharges']\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])  # transforma a coluna de string para numérico\n",
    "\n",
    "df['Churn'][df['Churn'] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df['Churn'][df['Churn'] == 'Yes'] = 1\n",
    "\n",
    "col = 'Dependents'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1\n",
    "\n",
    "col = 'Partner'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1 \n",
    "\n",
    "col = 'PaperlessBilling'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1  \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "col = 'TechSupport'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'StreamingTV'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'StreamingMovies'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'Contract'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_Contract = {'Month-to-month': 0, 'Two year': 2, 'One year': 1}\n",
    "\n",
    "col = 'PaymentMethod'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_PaymentMethod = {'Electronic check': 2, 'Mailed check': 3, 'Bank transfer (automatic)': 0, 'Credit card (automatic)': 1}\n",
    "\n",
    "col = 'gender'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'Male': 1, 'Female': 0}\n",
    "\n",
    "col = 'InternetService'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_PaymentMethod = {'Fiber optic': 1, 'DSL': 0, 'No': 2}\n",
    "\n",
    "col = 'OnlineBackup'\n",
    "le.fit(df[col])\n",
    "df.at[:,col] = le.transform(df[col])\n",
    "dict_TechSupport = {'No': 0, 'Yes': 2, 'No internet service': 1}\n",
    "\n",
    "col = 'PhoneService'\n",
    "df[col][df[col] == 'No'] = 0     # atriui 0 onde era 'No'\n",
    "df[col][df[col] == 'Yes'] = 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "#       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "#       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "\n",
    "features = ['TechSupport', 'Contract', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen', 'Partner', 'StreamingMovies', 'gender']\n",
    "y = df['Churn']\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHE = False\n",
    "if OHE:\n",
    "    col = 'Contract'\n",
    "    df_ohe = df[features]\n",
    "    ohe = OneHotEncoder(sparse=False) # categorical_features = boolean...\n",
    "    # for col in features_ohe:\n",
    "    le.fit(df[col])\n",
    "    col2 = col + '_e'\n",
    "    df.at[:,col2] = le.transform(df[col])\n",
    "    colunas = list(df.groupby([col, col2]).max().index.levels[0])         \n",
    "\n",
    "    X_ohe = ohe.fit_transform(df[col2].values.reshape(-1, 1)) # It returns an numpy array                \n",
    "    new = pd.DataFrame(X_ohe, columns=colunas, index=df.index)\n",
    "    df_ohe = pd.merge(new, df_ohe, how='inner', left_index=True, right_index=True)\n",
    "    # df = df_ohe.copy()\n",
    "    df = df_ohe.drop(col, axis=1)\n",
    "else:\n",
    "    df = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = False\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_features=5, n_jobs = -1, random_state = 0)  # n_estimators=600, \n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate = 0.1, max_depth = 4, random_state = 0)\n",
    "# clf = KNeighborsClassifier(n_neighbors = 4)\n",
    "# clf = LogisticRegression(C=0.1)\n",
    "\n",
    "# norm = True\n",
    "# clf = MLPClassifier(hidden_layer_sizes = [100, 100], solver='adam',  activation = 'tanh', alpha=0.00001, random_state = 0)   \n",
    "   \n",
    "# Fit\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "if norm:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_proba_lr = clf.predict_proba(X_test)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr[:,1])\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "clr = classification_report(y_test, y_predicted, target_names = ['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "score train: 0.8451344187807649\nscore test: 0.7847813742191937\nAUC 0.8270091551381591\n[[1141  157]\n [ 222  241]]\n              precision    recall  f1-score   support\n\n           0       0.84      0.88      0.86      1298\n           1       0.61      0.52      0.56       463\n\n    accuracy                           0.78      1761\n   macro avg       0.72      0.70      0.71      1761\nweighted avg       0.78      0.78      0.78      1761\n\n"
    }
   ],
   "source": [
    "print('score train:', clf.score(X_train, y_train))\n",
    "print('score test:', clf.score(X_test, y_test))\n",
    "print('AUC', roc_auc_lr)\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print(clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bitaf526a739cc24cf3b62b1505acdc52e6",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}